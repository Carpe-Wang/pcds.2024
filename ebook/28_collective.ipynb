{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121561ab-2583-41a9-95bb-3dbfc693b2a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collective Operations\n",
    "\n",
    "Collective operators use the entire communicator to perform:\n",
    "\n",
    "* Synchronization - processes wait until all members of the group have reached the synchronization point.\n",
    "* Data Movement - broadcast, scatter/gather, all to all.\n",
    "* Collective Computation (reductions) - one member of the group collects data from the other members and performs an operation (min, max, add, multiply, etc.) on that data.\n",
    "\n",
    "~\n",
    "\n",
    "<img src=\"https://hpc-tutorials.llnl.gov/mpi/images/collective_comm.gif\" width=512 />\n",
    "\n",
    "An MPI barrier can be through of as a synchronous collective message with no data.\n",
    "\n",
    "> `MPI_barrier(com)`: Synchronization operation. Creates a barrier synchronization in a group. Each task, when reaching the MPI_Barrier call, blocks until all tasks in the group reach the same MPI_Barrier call. Then all tasks are free to proceed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe2bd4-a591-4a74-937f-bc21158a1416",
   "metadata": {},
   "source": [
    "#### All Reduce\n",
    "\n",
    "This section drawn  from https://tech.preferred.jp/en/blog/technologies-behind-distributed-deep-learning-allreduce/.\n",
    "\n",
    "The critical operation in distributed deep-learning has become all-readuce.\n",
    "\n",
    "<img src=\"https://tech.preferred.jp/wp-content/uploads/2018/07/fig_1.png\" width=386 />\n",
    "\n",
    "The blog states --\n",
    "> In synchronized data-parallel distributed deep learning, the major computation steps are:\n",
    "> 1. Compute the gradient of the loss function using a minibatch on each GPU.\n",
    "> 2. Compute the mean of the gradients by inter-GPU communication.\n",
    "> 3. Update the model.\n",
    "\n",
    "This is an early effort (2017) in the space. It goes on to describe the ring algorithm, which has been used for a long time in HPC.  It takes two passes around the ring.\n",
    "  * The first collects one element per node. $O(n^2)$ messages in $n-1$ steps.\n",
    "  * The next distributes data to each node.  Same complexity.\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee95d1-a7f0-4799-abb1-fcf4317e1399",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-hwfc8HGjvbOpUR4.png\" width=386 />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
